%------------------------
\section{Preliminaries and Notation}
\label{sec:prelim}
%------------------------
We work with points from the $d$-dimensional Euclidean space $\R^d$ for integer
$d > 0$. Each point is associated with a positive integral weight ($1$ if
unspecified).  For points $x,y \in \R^d$, let $D(x,y) =\edist{x}{y}$ denote the
Euclidean distance between $x$ and $y$.  Extending this notation, the distance
from a point $x \in \R^d$ to a point set $\Psi \subset \R^d$ is
$D(x,\Psi) = \min_{\psi \in \Psi}\edist{x}{\psi}$.  In this notation, the
\emph{$k$-means clustering problem} is as follows:

%-----------------------
\begin{problem}[$k$-means Clustering] 
  Given a set $P \subseteq \R^d$ with $n$ points and a weight function
  $w\!: P \to \Z^+$, find a point set $\Psi \subseteq \R^d$, $|\Psi| = k$, that
  minimizes the objective function
\[
\phi_{\Psi}(P) = \sum_{x \in P} w(x) \cdot D^2(x,\Psi) = \sum_{x \in
  P}\min_{\psi \in \Psi} \left (w(x) \cdot {\edist{x}{\psi}}^2 \right).
\]
\end{problem}
%-----------------------

\noindent\textbf{Streams:} A stream $\stream = e_1, e_2, \ldots$ is an ordered
sequence of points, where $e_i$ is the $i$-th point observed by the algorithm.
For $t > 0$, let $\stream(t)$ denote the first $t$ entries of the stream:
$e_1, e_2, \ldots, e_t$. For $0 < i \le j$, let $\stream(i,j)$ denote the
substream $e_i, e_{i+1}, \ldots, e_j$.
Define $S = \stream(1,n)$ be the whole stream observed until $e_n$, where $n$
is, as before, the total number of points observed so far.

% We have written our analysis as if a query for cluster centers arrives every $q$ points. 
% {\color{blue} This parameter ($q$) captures the query rate in the most basic terms, we note that our results on the amortized query processing time still hold as long as the average number of points between two queries is $q$. The reason is that the cost of answering each query does not relate to when the query arrives, and the total query cost is simply the number of queries times the cost of each query.  Suppose that the queries arrived according to a different probability distribution, such that the expected interval between two queries is $q$ points. Then, the same results will hold in expectation.}
%-------------------------------------------------- 


%------------------------------------------------------
\noindent\textbf{\kmpp Algorithm:}
%------------------------------------------------------
Our algorithms rely on a batch algorithm as a subroutine: \kmpp algorithm~\cite{AV07}, 
which has the following properties:
%------------------------------------------------------
\begin{theorem}[Theorem 3.1 in \cite{AV07}]
\label{theo:kmeans++}
On an input set of $n$ points $P \subseteq \R^d$, the $k$-means++ algorithm returns a set
$\Psi$ of $k$ centers such that $\expct{\phi_{\Psi}(P)} \le 8(\ln k + 2) \cdot \phi_{OPT}(P)$ where $\phi_{OPT}(P)$ is
the optimal $k$-means clustering cost for $P$. The time complexity of the
algorithm is $O(kdn)$.
\end{theorem}
%------------------------------------------------------

\noindent\textbf{Coresets and Their Properties:}
Our clustering method builds on the concept of a \emph{coreset}, a small-space
representation of a weighted point set that (approximately) preserves desirable
properties of the original point set.  A variant suitable for $k$-means
clustering is as follows:
%-----------------------
\begin{definition}[$k$-means Coreset]
\label{defn:coreset}
For a weighted point set $P \subseteq \R^d$, integer $k > 0$, and parameter
$0 < \eps < 1$, a weighted set $C \subseteq \R^d$ is said to be a
$(k, \eps)$-coreset of $P$ for the $k$-means metric, if for any set $\Psi$
of $k$ points in $\R^d$, we have
\[(1-\eps) \cdot \phi_{\Psi}(P) \le \phi_{\Psi}(C) \le (1+\eps) \cdot \phi_{\Psi}(P)\]
\end{definition}
%-----------------------

Throughout, we use the term ``coreset'' to always refer to a $k$-means coreset.
When $k$ is clear from the context, we simply say an $\eps$-coreset.  For
integer $k > 0$, parameter $0 < \eps < 1$, and weighted point set
$P \subseteq \R^d$, we use the notation $\coreset(k, \eps, P)$ to mean a
$(k,\eps)$-coreset of $P$. We use the following observations from~\cite{HM04}.

%-----------------------
\begin{observation}[\cite{HM04}]
\label{obs:coreset1}
If $C_1$ and $C_2$ are each $(k,\eps)$-coresets for disjoint multi-sets $P_1$
and $P_2$ respectively, then $C_1 \cup C_2$ is a $(k, \eps)$-coreset for
$P_1 \cup P_2$.
\end{observation}
%-----------------------

%-----------------------
\begin{observation}[\cite{HM04}]
  \label{obs:coreset2}
  Let $k$ be fixed.  If $C_1$ is $\eps_1$-coreset for $C_2$, and $C_2$ is a
  $\eps_2$-coreset for $P$, then $C_1$ is a $((1+\eps_1)(1+\eps_2)-1)$-coreset
  for $P$.
\end{observation}
%-----------------------

\remove{
\begin{proof}
  We prove this by induction using the proposition: \emph{For a point set $P$,
    if $C = \coreset(k, \eps, \ell, P)$, then
    $C = \coreset(k, \eps', P)$ where
    $\eps' = \left(1+\eps \right)^{\ell} - 1$.}  

  To prove the base case of $\ell = 0$, consider that, by definition,
  $\coreset(k,\eps, 0, P) = P$, and $\coreset(k, 0, P) = P$.

  Now consider integer $L > 0$. Suppose that for each positive integer
  $\ell < L$, ${\cal P}(\ell)$ was true. The task is to prove ${\cal P}(L)$.
  Suppose $C = \coreset(k, \eps, L, P)$. Then there must be an arbitrary
  partition of $P$ into sets $P_1, P_2, \ldots, P_q$ such that
  $\cup_{i=1}^q P_i = P$. For $i=1\ldots q$, let
  $C_i = \coreset(k, \eps, \ell_i, P_i)$ for $\ell_i < L$. Then $C$ must be
  of the form $\coreset(k, \eps, \cup_{i=1}^q C_i)$.

  By the inductive hypothesis, we know that $C_i=\coreset(k, \eps_i, P_i)$
  where $\eps_i = \left(1+\eps \right)^{\ell_i} - 1$. By the definition
  of a coreset and using $\ell_i \le (L-1)$, it is also true that
  $C_i = \coreset(k, \eps'', P_i)$ where
  $\eps'' = \left(1+\eps \right)^{(L-1)} - 1$.  Let
  $C' = \cup_{i=1}^q C_i$.  From Observation~\ref{obs:coreset1}, and using
  $P = \cup_{i=1}^q P_i$, it must be true that $C'= \coreset(k, \eps'', P)$.
  Since $C=\coreset(k,\eps,C')$ and using Observation~\ref{obs:coreset2}, we
  get $C=\coreset(k, \gamma, P)$ where
  $\gamma=(1+\eps)(1+\eps'')-1$. Simplifying, we get
  $\gamma=(1+\eps)(1+ \left(1+\eps \right)^{(L-1)} - 1)-1 =
  \left(1+\eps \right )^L - 1$.
  This proves the inductive case for ${\cal P}(L)$, which completes the proof.
\end{proof}
%----------------
}

While our algorithms can work with any method for constructing coresets, 
an algorithm due to ~\cite{FSS13} by Feldman, Schimidt and Sohler provides the following
guarantees, which is best coreset construction algorithm from our knowledge:
%-------------------------
\begin{theorem}[\cite{FSS13} Corollary $4.5$]
\label{theo:coreset-build}
Given a point set $P$ with $n$ points, there exists an algorithm to compute $\coreset(k, \epsilon, P)$ 
with size $O(k / \epsilon^2)$. 
Let the coreset size be denoted by $m$, then the time complexity of constructing the coreset is $O(dnm)$. 
\end{theorem}
%-------------------------
